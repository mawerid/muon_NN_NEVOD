{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:41:16.675270618Z",
     "start_time": "2024-01-21T09:41:08.853036698Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class GraphNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        self.conv1 = GCNConv(input_size, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv3 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv4 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv5 = GCNConv(hidden_size, output_size)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # GNN layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(getattr(self, f'conv{i + 1}')(x, edge_index))\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Assuming you have a dataset with input and output points\n",
    "# You should convert your data to PyTorch Geometric format, e.g., using `torch_geometric.data.Data` class\n",
    "\n",
    "# Example data preparation\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Assuming your input and output points are of size 672\n",
    "input_size = 672\n",
    "\n",
    "num_points = 672\n",
    "input_points = torch.randn(num_points, input_size)  # Random input data\n",
    "output_points = torch.randint(0, 2, (num_points,))   # Random binary classification labels\n",
    "\n",
    "# Construct PyTorch Geometric Data object\n",
    "edge_index = torch.zeros((2, num_points), dtype=torch.long)\n",
    "for i in range(num_points):\n",
    "    edge_index[0, i] = i\n",
    "    edge_index[1, i] = (i + 1) % num_points\n",
    "\n",
    "data = Data(x=input_points, edge_index=edge_index, y=output_points)\n",
    "\n",
    "# Instantiate the GNN model\n",
    "hidden_size = 128\n",
    "output_size = 2  # Binary classification\n",
    "num_layers = 5\n",
    "\n",
    "model = GraphNeuralNetwork(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 100\n",
    "# for epoch in range(num_epochs):\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(data)\n",
    "#     loss = criterion(output, data.y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "# \n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# After training, you can use the trained model for predictions on new data\n",
    "# For example, you can do something like:\n",
    "# new_data = ...  # Prepare new data in PyTorch Geometric format\n",
    "# predicted_labels = model(new_data).argmax(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43msummary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_available\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torchsummary/torchsummary.py:72\u001B[0m, in \u001B[0;36msummary\u001B[0;34m(model, input_size, batch_size, device)\u001B[0m\n\u001B[1;32m     68\u001B[0m model\u001B[38;5;241m.\u001B[39mapply(register_hook)\n\u001B[1;32m     70\u001B[0m \u001B[38;5;66;03m# make a forward pass\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# print(x.shape)\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# remove these hooks\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m h \u001B[38;5;129;01min\u001B[39;00m hooks:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[2], line 19\u001B[0m, in \u001B[0;36mGraphNeuralNetwork.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[0;32m---> 19\u001B[0m     x, edge_index \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m, data\u001B[38;5;241m.\u001B[39medge_index\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# GNN layers\u001B[39;00m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers):\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Tensor' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(input_size,), device='cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:29:39.452675593Z",
     "start_time": "2024-01-21T09:29:38.408038026Z"
    }
   },
   "id": "7692cdb4315ed3e7",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(GraphNet, self).__init__()\n",
    "\n",
    "        # Define graph convolutional layers\n",
    "        self.conv1 = GCNConv(input_size, hidden_sizes[0])\n",
    "        self.conv2 = GCNConv(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.conv3 = GCNConv(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.conv4 = GCNConv(hidden_sizes[2], hidden_sizes[3])\n",
    "        self.conv5 = GCNConv(hidden_sizes[3], hidden_sizes[4])\n",
    "\n",
    "        # Fully connected layer for regression\n",
    "        self.fc = nn.Linear(hidden_sizes[4], output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Apply graph convolutional layers\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.relu(self.conv5(x, edge_index))\n",
    "\n",
    "        # Global mean pooling to get a fixed-size output\n",
    "        x = torch.mean(x, dim=0)\n",
    "\n",
    "        # Fully connected layer for regression\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define your dataset and DataLoader here (assuming you have a PyTorch Geometric dataset)\n",
    "\n",
    "# Example usage:\n",
    "input_size = 672\n",
    "hidden_sizes = [128, 128, 64, 32, 16]\n",
    "output_size = 6  # Assuming you want to regress 6 parameters\n",
    "model = GraphNet(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train your model using your dataset and DataLoader\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch_data in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(batch_data)\n",
    "#         loss = criterion(output, batch_data.y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:41:16.729026825Z",
     "start_time": "2024-01-21T09:41:16.720163247Z"
    }
   },
   "id": "73f77ad3a13c5259",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'+--------------------+----------------------+----------------+----------+\\n| Layer              | Input Shape          | Output Shape   | #Param   |\\n|--------------------+----------------------+----------------+----------|\\n| GraphNeuralNetwork | [672, 672]           | [672, 2]       | 135,938  |\\n| ├─(conv1)GCNConv   | [672, 672], [2, 672] | [672, 128]     | 86,144   |\\n| ├─(conv2)GCNConv   | [672, 128], [2, 672] | [672, 128]     | 16,512   |\\n| ├─(conv3)GCNConv   | [672, 128], [2, 672] | [672, 128]     | 16,512   |\\n| ├─(conv4)GCNConv   | [672, 128], [2, 672] | [672, 128]     | 16,512   |\\n| ├─(conv5)GCNConv   | [672, 128], [2, 672] | [672, 2]       | 258      |\\n+--------------------+----------------------+----------------+----------+'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import summary\n",
    "\n",
    "summary(model, data, max_depth=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:55:48.253750246Z",
     "start_time": "2024-01-21T09:55:48.205659442Z"
    }
   },
   "id": "139d0374e40dec7a",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GraphNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        self.conv1 = GCNConv(input_size, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv3 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv4 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv5 = GCNConv(hidden_size, output_size)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # GNN layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(getattr(self, f'conv{i + 1}')(x, edge_index))\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Assuming you have a dataset with input and output points\n",
    "# You should convert your data to PyTorch Geometric format, e.g., using `torch_geometric.data.Data` class\n",
    "\n",
    "# Example data preparation\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Assuming your input and output points are of size 672\n",
    "num_points = 672\n",
    "input_points = torch.randn(num_points, input_size)  # Random input data\n",
    "output_points = torch.randint(0, 2, (num_points,))   # Random binary classification labels\n",
    "\n",
    "# Construct PyTorch Geometric Data object\n",
    "edge_index = torch.zeros((2, num_points), dtype=torch.long)\n",
    "for i in range(num_points):\n",
    "    edge_index[0, i] = i\n",
    "    edge_index[1, i] = (i + 1) % num_points\n",
    "\n",
    "data = Data(x=input_points, edge_index=edge_index, y=output_points)\n",
    "\n",
    "# Instantiate the GNN model\n",
    "input_size = 672\n",
    "hidden_size = 128\n",
    "output_size = 2  # Binary classification\n",
    "num_layers = 5\n",
    "\n",
    "model = GraphNeuralNetwork(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "# num_epochs = 100\n",
    "# for epoch in range(num_epochs):\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(data)\n",
    "#     loss = criterion(output, data.y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "# \n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:55:27.132925948Z",
     "start_time": "2024-01-21T09:55:27.098015715Z"
    }
   },
   "id": "7e9fb688864762c2",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNRegressionModel(\n",
      "  (conv1): GCNConv(672, 128)\n",
      "  (conv2): GCNConv(128, 256)\n",
      "  (conv3): GCNConv(256, 128)\n",
      "  (conv4): GCNConv(128, 64)\n",
      "  (conv5): GCNConv(64, 32)\n",
      "  (fc): Linear(in_features=32, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GNNRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(GNNRegressionModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Define graph convolutional layers\n",
    "        self.conv1 = GCNConv(input_size, hidden_sizes[0])\n",
    "        self.conv2 = GCNConv(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.conv3 = GCNConv(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.conv4 = GCNConv(hidden_sizes[2], hidden_sizes[3])\n",
    "        self.conv5 = GCNConv(hidden_sizes[3], hidden_sizes[4])\n",
    "\n",
    "        # Fully connected layer for regression output\n",
    "        self.fc = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # Apply graph convolutional layers with activation functions\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.relu(self.conv5(x, edge_index))\n",
    "\n",
    "        # Global mean pooling to aggregate node-level information\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # Fully connected layer for regression output\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 672\n",
    "hidden_sizes = [128, 256, 128, 64, 32]  # Adjust as needed\n",
    "output_size = 6  # Number of regression parameters\n",
    "\n",
    "# Create an instance of the GNN model\n",
    "model = GNNRegressionModel(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Print model summary\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:52:55.187206972Z",
     "start_time": "2024-01-21T09:52:55.138136598Z"
    }
   },
   "id": "a1301b7899ece527",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Print model summary\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m summary_text \u001B[38;5;241m=\u001B[39m \u001B[43mtorchsummary\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msummary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(summary_text)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torchsummary/torchsummary.py:72\u001B[0m, in \u001B[0;36msummary\u001B[0;34m(model, input_size, batch_size, device)\u001B[0m\n\u001B[1;32m     68\u001B[0m model\u001B[38;5;241m.\u001B[39mapply(register_hook)\n\u001B[1;32m     70\u001B[0m \u001B[38;5;66;03m# make a forward pass\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# print(x.shape)\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# remove these hooks\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m h \u001B[38;5;129;01min\u001B[39;00m hooks:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[12], line 24\u001B[0m, in \u001B[0;36mGNNRegressionModel.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[0;32m---> 24\u001B[0m     x, edge_index, batch \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m, data\u001B[38;5;241m.\u001B[39medge_index, data\u001B[38;5;241m.\u001B[39mbatch\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;66;03m# Apply graph convolutional layers with activation functions\u001B[39;00m\n\u001B[1;32m     27\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x, edge_index))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Tensor' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "summary_text = torchsummary.summary(model, (input_size,))\n",
    "print(summary_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:54:47.697223257Z",
     "start_time": "2024-01-21T09:54:47.530422328Z"
    }
   },
   "id": "78ab995017ecf2f5",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3f95efcd3b7aa1ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
