{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:11:46.866977Z",
     "start_time": "2023-05-30T11:11:42.552362Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from scipy import stats"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:11:51.370853Z",
     "start_time": "2023-05-30T11:11:48.511490Z"
    }
   },
   "source": [
    "df_x = pd.read_csv('../data/dataset_02/data.csv')\n",
    "df_y = pd.read_csv('../data/dataset_02/answer.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:11:52.224412Z",
     "start_time": "2023-05-30T11:11:51.922631Z"
    }
   },
   "source": [
    "df_x = df_x.drop(labels=['Unnamed: 0'], axis=1)\n",
    "df_x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:11:52.942165Z",
     "start_time": "2023-05-30T11:11:52.919365Z"
    }
   },
   "source": [
    "df_y = df_y.drop(labels=['Unnamed: 0'], axis=1)\n",
    "df_y"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:11:54.552918Z",
     "start_time": "2023-05-30T11:11:54.323805Z"
    }
   },
   "source": [
    "df = pd.concat([df_x, df_y], axis=1)\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:11:55.153004Z",
     "start_time": "2023-05-30T11:11:55.144209Z"
    }
   },
   "source": [
    "labels = [str(i) for i in range(672)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:11:56.836641Z",
     "start_time": "2023-05-30T11:11:55.650797Z"
    }
   },
   "source": [
    "df = df.drop_duplicates(subset=labels, ignore_index=True)\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:11:56.947301Z",
     "start_time": "2023-05-30T11:11:56.839387Z"
    }
   },
   "source": [
    "df_x = df.drop(labels=['x1', 'y1', 'z1', 'x2', 'y2', 'z2'], axis=1)\n",
    "df_x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:11:57.660164Z",
     "start_time": "2023-05-30T11:11:57.628313Z"
    }
   },
   "source": [
    "df_y = df.drop(labels=labels, axis=1)\n",
    "df_y"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:11:58.448949Z",
     "start_time": "2023-05-30T11:11:58.433769Z"
    }
   },
   "source": [
    "df_x = np.reshape(df_x.to_numpy(), (-1, 24, 28, 1))\n",
    "df_x.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:11:59.728257Z",
     "start_time": "2023-05-30T11:11:59.711464Z"
    }
   },
   "source": [
    "df_y = df_y.to_numpy()\n",
    "df_y"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:12:01.102721Z",
     "start_time": "2023-05-30T11:12:00.681011Z"
    }
   },
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(df_x, df_y, train_size=0.9)\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x,\n",
    "                                                    train_y,\n",
    "                                                    test_size=0.33)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:12:01.638784Z",
     "start_time": "2023-05-30T11:12:01.628818Z"
    },
    "scrolled": true
   },
   "source": [
    "print(train_x.shape), print(train_y.shape)\n",
    "print(valid_x.shape), print(valid_y.shape)\n",
    "print(test_x.shape), print(test_y.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:12:03.491873Z",
     "start_time": "2023-05-30T11:12:03.060280Z"
    }
   },
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(24, 28, 1)),\n",
    "    layers.Conv2D(32, (7, 7), activation=\"relu\", data_format='channels_last'),\n",
    "    layers.MaxPooling2D((2, 2), strides=2),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\", data_format='channels_last'),\n",
    "    layers.MaxPooling2D((2, 2), strides=2),\n",
    "    layers.Flatten(),\n",
    "    # layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    # layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(6, activation='linear')\n",
    "])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:12:04.199744Z",
     "start_time": "2023-05-30T11:12:04.164609Z"
    }
   },
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.MeanSquaredError(),\n",
    "              metrics=[keras.metrics.MeanSquaredError()])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:12:05.052889Z",
     "start_time": "2023-05-30T11:12:05.007700Z"
    }
   },
   "source": [
    "model.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "checkpoint_name = 'weights/Weights-{epoch:03d}--{val_loss:.5f}.hdf5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_name,\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=1,\n",
    "                                             save_best_only=True,\n",
    "                                             mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "history = model.fit(train_x,\n",
    "                    train_y,\n",
    "                    batch_size=64,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(valid_x, valid_y))  # ,\n",
    "# callbacks=callbacks_list)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "history.history"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "sb.scatterplot(\n",
    "    {'loss': history.history['loss'], 'validation loss': history.history['val_loss']})\n",
    "plt.ylabel(\"Значение функции потерь\")\n",
    "plt.xlabel(\"Номер эпохи\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "sb.scatterplot({'mean_squared_error': history.history['mean_squared_error'],\n",
    "               'val_mean_squared_error': history.history['val_mean_squared_error']})"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load wights file of the best model :\n",
    "wights_file = '../logs/weights_model_01/Weights-049--17.80290.hdf5'  # choose the best checkpoint\n",
    "model.load_weights(wights_file)  # load it\n",
    "model.compile(loss=keras.losses.MeanSquaredError(\n",
    "), optimizer=keras.optimizers.Adam(), metrics=[keras.metrics.MeanSquaredError()])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "model.summary(expand_nested=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer)\n",
    "    try:\n",
    "        print(\"    \", layer.activation)\n",
    "    except AttributeError:\n",
    "        print('   no activation attribute')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def to_spherical(coor):\n",
    "    vector = np.array(\n",
    "        [(coor[3]-coor[0]), (coor[4]-coor[1]), (coor[5]-coor[2])])\n",
    "    vectorsphere = np.array([np.sqrt((vector**2).sum()), (np.arctan(np.sqrt(\n",
    "        coor[0]**2 + coor[1]**2)/coor[2])*180/np.pi), (np.arctan(coor[1]/coor[0])*180/np.pi)])\n",
    "    return vectorsphere"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "xtr = model.predict(X_train.iloc[:1])\n",
    "xtr"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
