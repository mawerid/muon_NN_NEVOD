{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:41:16.675270618Z",
     "start_time": "2024-01-21T09:41:08.853036698Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class GraphNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        self.conv1 = GCNConv(input_size, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv3 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv4 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv5 = GCNConv(hidden_size, output_size)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # GNN layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(getattr(self, f'conv{i + 1}')(x, edge_index))\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Assuming you have a dataset with input and output points\n",
    "# You should convert your data to PyTorch Geometric format, e.g., using `torch_geometric.data.Data` class\n",
    "\n",
    "# Example data preparation\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Assuming your input and output points are of size 672\n",
    "input_size = 672\n",
    "\n",
    "num_points = 672\n",
    "input_points = torch.randn(num_points, input_size)  # Random input data\n",
    "output_points = torch.randint(0, 2, (num_points,))   # Random binary classification labels\n",
    "\n",
    "# Construct PyTorch Geometric Data object\n",
    "edge_index = torch.zeros((2, num_points), dtype=torch.long)\n",
    "for i in range(num_points):\n",
    "    edge_index[0, i] = i\n",
    "    edge_index[1, i] = (i + 1) % num_points\n",
    "\n",
    "data = Data(x=input_points, edge_index=edge_index, y=output_points)\n",
    "\n",
    "# Instantiate the GNN model\n",
    "hidden_size = 128\n",
    "output_size = 2  # Binary classification\n",
    "num_layers = 5\n",
    "\n",
    "model = GraphNeuralNetwork(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 100\n",
    "# for epoch in range(num_epochs):\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(data)\n",
    "#     loss = criterion(output, data.y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "# \n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# After training, you can use the trained model for predictions on new data\n",
    "# For example, you can do something like:\n",
    "# new_data = ...  # Prepare new data in PyTorch Geometric format\n",
    "# predicted_labels = model(new_data).argmax(dim=1)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "summary(model, input_size=(input_size,), device='cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:29:39.452675593Z",
     "start_time": "2024-01-21T09:29:38.408038026Z"
    }
   },
   "id": "7692cdb4315ed3e7",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(GraphNet, self).__init__()\n",
    "\n",
    "        # Define graph convolutional layers\n",
    "        self.conv1 = GCNConv(input_size, hidden_sizes[0])\n",
    "        self.conv2 = GCNConv(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.conv3 = GCNConv(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.conv4 = GCNConv(hidden_sizes[2], hidden_sizes[3])\n",
    "        self.conv5 = GCNConv(hidden_sizes[3], hidden_sizes[4])\n",
    "\n",
    "        # Fully connected layer for regression\n",
    "        self.fc = nn.Linear(hidden_sizes[4], output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Apply graph convolutional layers\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.relu(self.conv5(x, edge_index))\n",
    "\n",
    "        # Global mean pooling to get a fixed-size output\n",
    "        x = torch.mean(x, dim=0)\n",
    "\n",
    "        # Fully connected layer for regression\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define your dataset and DataLoader here (assuming you have a PyTorch Geometric dataset)\n",
    "\n",
    "# Example usage:\n",
    "input_size = 672\n",
    "hidden_sizes = [128, 128, 64, 32, 16]\n",
    "output_size = 6  # Assuming you want to regress 6 parameters\n",
    "model = GraphNet(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train your model using your dataset and DataLoader\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch_data in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(batch_data)\n",
    "#         loss = criterion(output, batch_data.y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:41:16.729026825Z",
     "start_time": "2024-01-21T09:41:16.720163247Z"
    }
   },
   "id": "73f77ad3a13c5259",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import summary\n",
    "\n",
    "summary(model, data, max_depth=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:55:48.253750246Z",
     "start_time": "2024-01-21T09:55:48.205659442Z"
    }
   },
   "id": "139d0374e40dec7a",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GraphNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        self.conv1 = GCNConv(input_size, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv3 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv4 = GCNConv(hidden_size, hidden_size)\n",
    "        self.conv5 = GCNConv(hidden_size, output_size)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # GNN layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(getattr(self, f'conv{i + 1}')(x, edge_index))\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Assuming you have a dataset with input and output points\n",
    "# You should convert your data to PyTorch Geometric format, e.g., using `torch_geometric.data.Data` class\n",
    "\n",
    "# Example data preparation\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Assuming your input and output points are of size 672\n",
    "num_points = 672\n",
    "input_points = torch.randn(num_points, input_size)  # Random input data\n",
    "output_points = torch.randint(0, 2, (num_points,))   # Random binary classification labels\n",
    "\n",
    "# Construct PyTorch Geometric Data object\n",
    "edge_index = torch.zeros((2, num_points), dtype=torch.long)\n",
    "for i in range(num_points):\n",
    "    edge_index[0, i] = i\n",
    "    edge_index[1, i] = (i + 1) % num_points\n",
    "\n",
    "data = Data(x=input_points, edge_index=edge_index, y=output_points)\n",
    "\n",
    "# Instantiate the GNN model\n",
    "input_size = 672\n",
    "hidden_size = 128\n",
    "output_size = 2  # Binary classification\n",
    "num_layers = 5\n",
    "\n",
    "model = GraphNeuralNetwork(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "# num_epochs = 100\n",
    "# for epoch in range(num_epochs):\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(data)\n",
    "#     loss = criterion(output, data.y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "# \n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:55:27.132925948Z",
     "start_time": "2024-01-21T09:55:27.098015715Z"
    }
   },
   "id": "7e9fb688864762c2",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GNNRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(GNNRegressionModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Define graph convolutional layers\n",
    "        self.conv1 = GCNConv(input_size, hidden_sizes[0])\n",
    "        self.conv2 = GCNConv(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.conv3 = GCNConv(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.conv4 = GCNConv(hidden_sizes[2], hidden_sizes[3])\n",
    "        self.conv5 = GCNConv(hidden_sizes[3], hidden_sizes[4])\n",
    "\n",
    "        # Fully connected layer for regression output\n",
    "        self.fc = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # Apply graph convolutional layers with activation functions\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.relu(self.conv5(x, edge_index))\n",
    "\n",
    "        # Global mean pooling to aggregate node-level information\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # Fully connected layer for regression output\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 672\n",
    "hidden_sizes = [128, 256, 128, 64, 32]  # Adjust as needed\n",
    "output_size = 6  # Number of regression parameters\n",
    "\n",
    "# Create an instance of the GNN model\n",
    "model = GNNRegressionModel(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Print model summary\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:52:55.187206972Z",
     "start_time": "2024-01-21T09:52:55.138136598Z"
    }
   },
   "id": "a1301b7899ece527",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torchsummary\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "summary_text = torchsummary.summary(model, (input_size,))\n",
    "print(summary_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T09:54:47.697223257Z",
     "start_time": "2024-01-21T09:54:47.530422328Z"
    }
   },
   "id": "78ab995017ecf2f5",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3f95efcd3b7aa1ea",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
